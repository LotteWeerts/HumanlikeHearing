{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import humanlikehearing\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Plotting\n",
    "\n",
    "Below you can find an example of how you can visualise the results from one of your experiments. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# First lets run a dummy experiment to obtain a results file.\n",
    "asr_system = humanlikehearing.asrsystem.DummyASR('')\n",
    "dataset = humanlikehearing.dataset.DummyDataSet('.')\n",
    "bandpass_test = humanlikehearing.testbattery.BandpassTest('results', sentences_per_condition=1)\n",
    "bandpass_test.run(asr_system, dataset)\n",
    "\n",
    "# Load the results file\n",
    "result_folder = bandpass_test._get_result_folder('standard')\n",
    "results = pd.read_pickle(os.path.join(result_folder, 'results.pk1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results file will have a multi index, which indicates the condition parameters. In this case, it contains the sentence id and the threshold used in the experiment for every row in the results file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([(0,  nan),\n",
       "            (0, 42.0),\n",
       "            (0, 41.0),\n",
       "            (0, 40.0),\n",
       "            (0, 39.0),\n",
       "            (0, 38.0),\n",
       "            (0, 37.0),\n",
       "            (0, 36.0),\n",
       "            (0, 35.0),\n",
       "            (0, 34.0),\n",
       "            (0, 33.0),\n",
       "            (0, 32.0),\n",
       "            (0, 31.0),\n",
       "            (0, 30.0),\n",
       "            (0, 29.0),\n",
       "            (0, 28.0),\n",
       "            (0, 27.0),\n",
       "            (0, 26.0),\n",
       "            (0, 25.0),\n",
       "            (0, 24.0),\n",
       "            (0, 23.0),\n",
       "            (0, 22.0),\n",
       "            (0, 21.0),\n",
       "            (0, 20.0),\n",
       "            (0, 19.0),\n",
       "            (0, 18.0),\n",
       "            (0, 17.0),\n",
       "            (0, 16.0),\n",
       "            (0, 15.0),\n",
       "            (0, 14.0),\n",
       "            (0, 13.0),\n",
       "            (0, 12.0),\n",
       "            (0, 11.0),\n",
       "            (0, 10.0),\n",
       "            (0,  9.0),\n",
       "            (0,  8.0),\n",
       "            (0,  7.0),\n",
       "            (0,  6.0),\n",
       "            (0,  5.0),\n",
       "            (0,  4.0)],\n",
       "           names=['sentence_id', 'bandpass_width_semitone'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outcomes of the experiments are stored in columns, the main one of interest is usually 'keyword accuracy':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['keyword_accuracy', 'predicted_transcription', 'transcription'], dtype='object')\n",
      "sentence_id  bandpass_width_semitone\n",
      "0            NaN                        1.0\n",
      "             42                         1.0\n",
      "             41                         1.0\n",
      "             40                         1.0\n",
      "             39                         1.0\n",
      "             38                         1.0\n",
      "             37                         1.0\n",
      "             36                         1.0\n",
      "             35                         1.0\n",
      "             34                         1.0\n",
      "             33                         1.0\n",
      "             32                         1.0\n",
      "             31                         1.0\n",
      "             30                         1.0\n",
      "             29                         1.0\n",
      "             28                         1.0\n",
      "             27                         1.0\n",
      "             26                         1.0\n",
      "             25                         1.0\n",
      "             24                         1.0\n",
      "             23                         1.0\n",
      "             22                         1.0\n",
      "             21                         1.0\n",
      "             20                         1.0\n",
      "             19                         1.0\n",
      "             18                         1.0\n",
      "             17                         1.0\n",
      "             16                         1.0\n",
      "             15                         1.0\n",
      "             14                         1.0\n",
      "             13                         1.0\n",
      "             12                         1.0\n",
      "             11                         1.0\n",
      "             10                         1.0\n",
      "             9                          1.0\n",
      "             8                          1.0\n",
      "             7                          1.0\n",
      "             6                          1.0\n",
      "             5                          1.0\n",
      "             4                          1.0\n",
      "Name: keyword_accuracy, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(results.columns)\n",
    "print(results['keyword_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas offers many ways of accessing a specific set of parameters when using a MultiIndex. One easy way to obtain for example all items with a threshold higher than 0.5 is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subset_results = results[results.index.get_level_values('bandpass_width_semitone') > 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To plot the results, simply select the keyword accuracy and plot. In this case, the output is a horizontal line since our DummyASR always predicts 'hello world' and the target transcription of the DummyDataSet is always 'hello world'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ffa51baa7f0>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(subset_results['keyword_accuracy'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Speech Reception Threshold Analysis\n",
    "\n",
    "To run the SRT analysis, first install psignifit following the installation instructions of that package:\n",
    "\n",
    "https://github.com/wichmann-lab/python-psignifit/wiki/Install\n",
    "\n",
    "Once installed, run a quick dummy experiment to obtain some SRT values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pip install https://github.com/wichmann-lab/python-psignifit/zipball/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "asr_system = humanlikehearing.asrsystem.DummyASR('')\n",
    "dataset = humanlikehearing.asrsystem.DummyDataSet('.')\n",
    "\n",
    "test_params = {\n",
    "    'cutoff_values': [0],\n",
    "    'region_width': 6,\n",
    "    'vocoder_types': ['retain_tfs_below_cutoff'],\n",
    "}\n",
    "\n",
    "tfs_test = humanlikehearing.testbattery.TemporalFineStructureTest(\n",
    "    'results', test_parameters=test_params, sentences_per_condition=1)           \n",
    "tfs_test.run(asr_system, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_folder = tfs_test._get_result_folder('standard')\n",
    "results = pd.read_pickle(os.path.join(result_folder, 'results.pk1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select a single condition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subset_results = results[(\n",
    "        (results.index.get_level_values('noise_type') == \"white_noise\") &\n",
    "        (results.index.get_level_values('vocoder_type') == \"retain_tfs_below_cutoff\") & \n",
    "        (results.index.get_level_values('cutoff_values') == \"0\") \n",
    ")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to select the SNRs and the keyword_accuracy to compute the SRTs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "srts = subset_results.index.get_level_values('SNR').values\n",
    "accuracy = subset_results['keyword_accuracy'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can fit the psychometric function to obtain an SRT (speech reception threshold). Note that you will likely get some warnings here since we are trying to fit a horizontal line! If you use real data these should disappear. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([], dtype=int64),)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lotteweerts/anaconda/envs/humanhearing/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "/Users/lotteweerts/anaconda/envs/humanhearing/lib/python3.6/site-packages/psignifit/likelihood.py:127: RuntimeWarning: invalid value encountered in subtract\n",
      "  p = p -sp.gammaln(n+v) - sp.gammaln(a) - sp.gammaln(b)\n",
      "/Users/lotteweerts/anaconda/envs/humanhearing/lib/python3.6/site-packages/psignifit/likelihood.py:222: RuntimeWarning: divide by zero encountered in log\n",
      "  prior = np.log(temp)\n",
      "/Users/lotteweerts/anaconda/envs/humanhearing/lib/python3.6/site-packages/psignifit/likelihood.py:121: RuntimeWarning: divide by zero encountered in log\n",
      "  p = p + k * np.log(psi) + (n-k)*np.log(1-psi)   # binomial model\n",
      "/Users/lotteweerts/anaconda/envs/humanhearing/lib/python3.6/site-packages/scipy/optimize/optimize.py:700: RuntimeWarning: invalid value encountered in subtract\n",
      "  np.max(np.abs(fsim[0] - fsim[1:])) <= fatol):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-15.783619633274157"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psignifit\n",
    "\n",
    "def fit_psychometric_function(\n",
    "    snrs, accuracy, sigmoid_name='logistic', \n",
    "    average_keywords_per_sentence=5, \n",
    "    srt_threshold=0.5, fast=False):\n",
    "\n",
    "    # psignifit assumes 'yes' or 'no' answers\n",
    "    accuracy *= average_keywords_per_sentence\n",
    "    nr_trials = np.ones(len(accuracy))*average_keywords_per_sentence\n",
    "    data = np.concatenate([snrs, accuracy, nr_trials]).reshape(3, -1).T\n",
    "    options = {\n",
    "        'sigmoidName': sigmoid_name,\n",
    "        'confP': [], #[0.95],\n",
    "        'threshPC': srt_threshold\n",
    "    }\n",
    "    \n",
    "    if fast:\n",
    "        fit = psignifit.psignifitFast\n",
    "    else:\n",
    "        fit = psignifit.psignifit\n",
    "    \n",
    "    result = fit(data, options) #psignifit(data, options)\n",
    "    return result['Fit'][0]\n",
    "\n",
    "fit_psychometric_function(srts, accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstEnv",
   "language": "python",
   "name": "firstenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
